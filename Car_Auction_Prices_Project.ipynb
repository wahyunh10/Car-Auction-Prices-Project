{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Car Auction Prices Project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUxRUXl0DYUy6MVxt/Pgak",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wahyunh10/Car-Auction-Prices-Project/blob/main/Car_Auction_Prices_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Car Auction Prices Project**"
      ],
      "metadata": {
        "id": "yKhrbC_qm4J9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this project, there are 4 steps that I do:**\n",
        "\n",
        "1. Data Preparation (Data Cleaning)\n",
        "  * Extract Raw Data\n",
        "  * Fill and Drop Null Values\n",
        "  * Standardization Values\n",
        "  * Load Clean Data to CSV and Local MySQL Database\n",
        "2. Exploration Data Analysis\n",
        "  * Find Insight using Matplotlib and Seaborn\n",
        "  * Outlier Analysis\n",
        "  * Find Best and Worst Seller using Quantile Analysis\n",
        "3. Machine Learning Modelling\n",
        "  * Prediction Prices Cars using Regression\n",
        "  * Clustering Quality of Cars using KMeans Clustering\n",
        "4. Hypothesis Testing using MannWhitneyU"
      ],
      "metadata": {
        "id": "bMe6_PsoocaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains historical car auction sales prices, scraped from the outside internet sources collected in 2015. This dataset taken from kaggle (https://www.kaggle.com/tunguz/used-car-auction-prices)."
      ],
      "metadata": {
        "id": "qMuGyksyo34q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset contains 491641 rows and 15 columns:\n",
        "\n",
        "* year : information of year production of the car\n",
        "* make : brand of the car\n",
        "* model : model of the brand car\n",
        "* trim : spesific model of the car\n",
        "* body : body type of the car\n",
        "* transmission : transmission type of the car\n",
        "* vin : unique id of the car\n",
        "* state : code state where the transaction happened\n",
        "* condition : rating condition of the car\n",
        "* odometer : total distance of the car\n",
        "* color : body color of the car\n",
        "* interior : interior color of the car\n",
        "* seller : place that sold the car\n",
        "* mmr : market price of the car\n",
        "* sellingprice : price of the car\n",
        "* saledate : date when the car sold"
      ],
      "metadata": {
        "id": "whXzS5CAo6yS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preparation**"
      ],
      "metadata": {
        "id": "E4u2NqEet2rJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3ca7QtQHm1KU"
      },
      "outputs": [],
      "source": [
        "# Import needed libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import raw data from csv**"
      ],
      "metadata": {
        "id": "u-jeL3XKt9tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_source = pd.read_csv(\"car_prices.csv\")\n",
        "df_source.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "Wh-FJGdjuBVR",
        "outputId": "3c5be254-08bc-461f-f15d-6d9183315e1d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   year   make                model        trim   body transmission  \\\n",
              "0  2015    Kia              Sorento          LX    SUV    automatic   \n",
              "1  2015    Kia              Sorento          LX    SUV    automatic   \n",
              "2  2014    BMW             3 Series  328i SULEV  Sedan    automatic   \n",
              "3  2015  Volvo                  S60          T5  Sedan    automatic   \n",
              "4  2014    BMW  6 Series Gran Coupe        650i  Sedan    automatic   \n",
              "\n",
              "                 vin state condition  odometer  color interior  \\\n",
              "0  5xyktca69fg566472    ca       5.0   16639.0  white    black   \n",
              "1  5xyktca69fg561319    ca       5.0    9393.0  white    beige   \n",
              "2  wba3c1c51ek116351    ca       4.5    1331.0   gray    black   \n",
              "3  yv1612tb4f1310987    ca       4.1   14282.0  white    black   \n",
              "4  wba6b2c57ed129731    ca       4.3    2641.0   gray    black   \n",
              "\n",
              "                                   seller    mmr  sellingprice  \\\n",
              "0                 kia motors america, inc  20500         21500   \n",
              "1                 kia motors america, inc  20800         21500   \n",
              "2  financial services remarketing (lease)  31900         30000   \n",
              "3                 volvo na rep/world omni  27500         27750   \n",
              "4  financial services remarketing (lease)  66000         67000   \n",
              "\n",
              "                                  saledate Unnamed: 16  \n",
              "0  Tue Dec 16 2014 12:30:00 GMT-0800 (PST)         NaN  \n",
              "1  Tue Dec 16 2014 12:30:00 GMT-0800 (PST)         NaN  \n",
              "2  Thu Jan 15 2015 04:30:00 GMT-0800 (PST)         NaN  \n",
              "3  Thu Jan 29 2015 04:30:00 GMT-0800 (PST)         NaN  \n",
              "4  Thu Dec 18 2014 12:30:00 GMT-0800 (PST)         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-553d7bef-6c82-41dd-8bf4-2379ebc13774\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>make</th>\n",
              "      <th>model</th>\n",
              "      <th>trim</th>\n",
              "      <th>body</th>\n",
              "      <th>transmission</th>\n",
              "      <th>vin</th>\n",
              "      <th>state</th>\n",
              "      <th>condition</th>\n",
              "      <th>odometer</th>\n",
              "      <th>color</th>\n",
              "      <th>interior</th>\n",
              "      <th>seller</th>\n",
              "      <th>mmr</th>\n",
              "      <th>sellingprice</th>\n",
              "      <th>saledate</th>\n",
              "      <th>Unnamed: 16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>Kia</td>\n",
              "      <td>Sorento</td>\n",
              "      <td>LX</td>\n",
              "      <td>SUV</td>\n",
              "      <td>automatic</td>\n",
              "      <td>5xyktca69fg566472</td>\n",
              "      <td>ca</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16639.0</td>\n",
              "      <td>white</td>\n",
              "      <td>black</td>\n",
              "      <td>kia motors america, inc</td>\n",
              "      <td>20500</td>\n",
              "      <td>21500</td>\n",
              "      <td>Tue Dec 16 2014 12:30:00 GMT-0800 (PST)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>Kia</td>\n",
              "      <td>Sorento</td>\n",
              "      <td>LX</td>\n",
              "      <td>SUV</td>\n",
              "      <td>automatic</td>\n",
              "      <td>5xyktca69fg561319</td>\n",
              "      <td>ca</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9393.0</td>\n",
              "      <td>white</td>\n",
              "      <td>beige</td>\n",
              "      <td>kia motors america, inc</td>\n",
              "      <td>20800</td>\n",
              "      <td>21500</td>\n",
              "      <td>Tue Dec 16 2014 12:30:00 GMT-0800 (PST)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2014</td>\n",
              "      <td>BMW</td>\n",
              "      <td>3 Series</td>\n",
              "      <td>328i SULEV</td>\n",
              "      <td>Sedan</td>\n",
              "      <td>automatic</td>\n",
              "      <td>wba3c1c51ek116351</td>\n",
              "      <td>ca</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1331.0</td>\n",
              "      <td>gray</td>\n",
              "      <td>black</td>\n",
              "      <td>financial services remarketing (lease)</td>\n",
              "      <td>31900</td>\n",
              "      <td>30000</td>\n",
              "      <td>Thu Jan 15 2015 04:30:00 GMT-0800 (PST)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>Volvo</td>\n",
              "      <td>S60</td>\n",
              "      <td>T5</td>\n",
              "      <td>Sedan</td>\n",
              "      <td>automatic</td>\n",
              "      <td>yv1612tb4f1310987</td>\n",
              "      <td>ca</td>\n",
              "      <td>4.1</td>\n",
              "      <td>14282.0</td>\n",
              "      <td>white</td>\n",
              "      <td>black</td>\n",
              "      <td>volvo na rep/world omni</td>\n",
              "      <td>27500</td>\n",
              "      <td>27750</td>\n",
              "      <td>Thu Jan 29 2015 04:30:00 GMT-0800 (PST)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2014</td>\n",
              "      <td>BMW</td>\n",
              "      <td>6 Series Gran Coupe</td>\n",
              "      <td>650i</td>\n",
              "      <td>Sedan</td>\n",
              "      <td>automatic</td>\n",
              "      <td>wba6b2c57ed129731</td>\n",
              "      <td>ca</td>\n",
              "      <td>4.3</td>\n",
              "      <td>2641.0</td>\n",
              "      <td>gray</td>\n",
              "      <td>black</td>\n",
              "      <td>financial services remarketing (lease)</td>\n",
              "      <td>66000</td>\n",
              "      <td>67000</td>\n",
              "      <td>Thu Dec 18 2014 12:30:00 GMT-0800 (PST)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-553d7bef-6c82-41dd-8bf4-2379ebc13774')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-553d7bef-6c82-41dd-8bf4-2379ebc13774 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-553d7bef-6c82-41dd-8bf4-2379ebc13774');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check length of every row in dataset\n",
        "idx = []\n",
        "for i in range (df_source.shape[0]):\n",
        "    l = len(df_source.iloc[i][0].split(','))\n",
        "    idx.append(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "X2C1jrTTEU7w",
        "outputId": "d73c6f47-5268-415f-f36a-bd571462e97f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-379626424125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_source\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_source\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'split'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check data after columns problem solved**"
      ],
      "metadata": {
        "id": "en09n5OkEXnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_info():\n",
        "    listkolom=[]\n",
        "    for i in (df.columns):\n",
        "        listkolom.append(i)\n",
        "\n",
        "    listtipe=[]\n",
        "    for i in (df.columns):\n",
        "        listtipe.append(df[i].dtypes)\n",
        "\n",
        "    nullmany = df.isnull().sum().values\n",
        "\n",
        "    nullpctx = []\n",
        "    for i in nullmany:\n",
        "        nullpctx.append(round(i/len(df),4)*100)\n",
        "\n",
        "    unik = df.nunique().values\n",
        "\n",
        "    samp = []\n",
        "    for i in df.columns:\n",
        "        samp.append(df[i].sample().values)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'dataFeatures' : listkolom,\n",
        "        'dataType' : listtipe,\n",
        "        'null' : nullmany,\n",
        "        'nullpct' : nullpctx,\n",
        "        'unique' : unik,\n",
        "        'SampleValue' : samp\n",
        "    })\n",
        "\n",
        "data_info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "i1KiEZc8EYY4",
        "outputId": "97e42727-3181-4ed7-dc46-369d1bba056d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4002d693ba52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     })\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mdata_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-4002d693ba52>\u001b[0m in \u001b[0;36mdata_info\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlistkolom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mlistkolom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> It looks that data successfully stored into dataframe, and only have 21 anomaly rows that stored in temp1 column. Column temp2 is empty and will be deleted later.\n",
        "\n"
      ],
      "metadata": {
        "id": "jf8Dc-wIEdRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Process to tackle columns overlapping problem**"
      ],
      "metadata": {
        "id": "bTTQMYcCE2GE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to make all value has lowercase word\n",
        "def LowerVal(col):\n",
        "    newval = []\n",
        "    for i in df[col].values:\n",
        "        if str(i)=='nan':\n",
        "            newval.append(np.nan)\n",
        "        else:\n",
        "            cap = str(i).lower()\n",
        "            newval.append(cap)\n",
        "    df[col]=newval"
      ],
      "metadata": {
        "id": "elZPnyPGEaOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to all objects columns\n",
        "col_to_clean = df.select_dtypes(include='object').columns\n",
        "for i in col_to_clean:\n",
        "    LowerVal(i)"
      ],
      "metadata": {
        "id": "IVQXC2Z0E5sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix some value in 'make' columns\n",
        "makeFix = []\n",
        "for i in range(df.shape[0]):\n",
        "    if str(df['make'][i]) == 'nan':\n",
        "        makeFix.append(np.nan)\n",
        "    else:\n",
        "        newMake = df['make'][i].split()[0]\n",
        "        makeFix.append(newMake)\n",
        "\n",
        "df['make'] = makeFix\n",
        "\n",
        "df.loc[df[df['make']=='Mercedes-b'].index,'make'] = 'Mercedes-benz'\n",
        "df.loc[df[df['make']=='Mercedes'].index,'make'] = 'Mercedes-benz'\n",
        "df.loc[df[df['make']=='Land'].index,'make'] = 'Landrover'\n",
        "df.loc[df[df['make']=='Chev'].index,'make'] = 'Chevrolet'"
      ],
      "metadata": {
        "id": "ZTG9E-nuE7ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['transmission'].value_counts()"
      ],
      "metadata": {
        "id": "6gEkoqVtE9Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> From transmission column value, we can take conclusion rows that have 'sedan' as it value is the anomaly rows."
      ],
      "metadata": {
        "id": "pyG_kta0FB5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take rows that have 'sedan' as it value\n",
        "enum=list(enumerate(df['transmission']=='sedan'))\n",
        "idx_inv = []\n",
        "for idx,val in enum:\n",
        "    if val == True:\n",
        "        idx_inv.append(idx)\n",
        "        \n",
        "inv_data = df.iloc[idx_inv]\n",
        "\n",
        "# drop body column in invalid dataframe\n",
        "inv_data.drop(['body'],1,inplace=True)\n",
        "inv_data.head()"
      ],
      "metadata": {
        "id": "j5IoTRdJFE0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> body column in invalid dataframe dropped because it contain wrong information"
      ],
      "metadata": {
        "id": "ZHI-Ebu9FGrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['temp2'],1,inplace=True)\n",
        "inv_data.columns=df.columns\n",
        "\n",
        "# Re-fill value for invalid rows\n",
        "newval = []\n",
        "for i in range (inv_data.shape[0]):\n",
        "    listedval = list(inv_data.iloc[i].values)\n",
        "    newval.append(listedval)\n",
        "    \n",
        "df.iloc[idx_inv] = newval\n",
        "df.drop(['temp1'],1,inplace=True)\n",
        "\n",
        "# Check dataframe after problem invalid value rows solved \n",
        "df.info()"
      ],
      "metadata": {
        "id": "1niPSepVFHnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Cleaning Process**"
      ],
      "metadata": {
        "id": "znOM-mqkFVKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check total null values in every column\n",
        "pd.isna(df).sum()"
      ],
      "metadata": {
        "id": "eHKgektOFiOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check and replace if there are '-' value in dataset.\n",
        "def StripVal(col):\n",
        "    newval = []\n",
        "    for i in df[col].values:\n",
        "        if str(i)=='—':\n",
        "            newval.append(np.nan)\n",
        "        else:\n",
        "            newval.append(i)\n",
        "    df[col]=newval"
      ],
      "metadata": {
        "id": "IPh9EXlOFkRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply StripVal function to every columns object\n",
        "col_obj = df.select_dtypes('object').columns\n",
        "for i in col_obj:\n",
        "    StripVal(i)"
      ],
      "metadata": {
        "id": "19RZgEL2Fki5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to drop selected rows\n",
        "def drop_val(col):\n",
        "    idx_to_drop = []\n",
        "    for i in col.index:\n",
        "        idx_to_drop.append(i)\n",
        "\n",
        "    df.drop(idx_to_drop,inplace=True)\n",
        "    df.reset_index(drop=True,inplace=True)"
      ],
      "metadata": {
        "id": "KDxhO-ZzFl7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If the car have no information about all of make, model, body, and trim columns so we cannot describe what car is it.\n",
        "\n",
        "dataNull = df[(df['make'].isna()) & (df['model'].isna()) & (df['body'].isna()) & (df['trim'].isna())]\n",
        "\n",
        "drop_val(dataNull)"
      ],
      "metadata": {
        "id": "EvKClqxbFodP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If the car does not have color or interior information, dropped because it haven't got enough information.\n",
        "\n",
        "data_no_color = df[(df['color'].isna()) | (df['interior'].isna())]\n",
        "\n",
        "drop_val(data_no_color)"
      ],
      "metadata": {
        "id": "rhkIjZLlFo-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change data type to number\n",
        "\n",
        "df['year'] = df['year'].astype('int')\n",
        "df['mmr'] = df['mmr'].astype('int')\n",
        "df['sellingprice'] = df['sellingprice'].astype('int')\n",
        "df['condition'] = df['condition'].astype('float')\n",
        "df['odometer'] = df['odometer'].astype('float')"
      ],
      "metadata": {
        "id": "FrVL2MB1Fqws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fixing date columns\n",
        "\n",
        "fixed_date = []\n",
        "for i in range(len(df['saledate'])):\n",
        "    date = df.saledate[i][:15]\n",
        "    fixed_date.append(date)\n",
        "    \n",
        "df['saledate'] = fixed_date\n",
        "df['saledate'] = pd.to_datetime(df['saledate'])\n",
        "\n",
        "date_not_use = df[(df['saledate'] < '2014-12-01')]  # Deleting this data because there aren't enough data for that range of date \n",
        "drop_val(date_not_use)                              # It can cause trouble to EDA and Machine Learning modelling"
      ],
      "metadata": {
        "id": "xcaAdSXJFss1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "wJA56rTKFwM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This table above show us statistical descriptive of the data, it give insight that some columns have unusual and potentially wrong data. For example:\n",
        "\n",
        "* odometer have min and max value too far from the quartile, make the spread of data become ugly and have too large outlier\n",
        "* mmr have minimal value so little that have to check again\n",
        "* sellingprice have min and max value too far from the quartile like odometer column."
      ],
      "metadata": {
        "id": "2Mlt8KaOFzZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixing Sellingprice column\n",
        "\n",
        "# Change column that have maximum sellingprice because its value is too big\n",
        "# After some check, there is only one column that has maximum sellingprice value, that column have 22800 mmr\n",
        "wr_val_sellingprice = df[df['sellingprice']==df['sellingprice'].max()].index\n",
        "\n",
        "# Because the value of mmr and sellingprice is usually not too far, so I remove one '0' at this cell of sellingprice column\n",
        "df.loc[wr_val_sellingprice,['sellingprice']] = 23000  \n",
        "\n",
        "# Delete data that have sellingprice below 100, because it doesn't make sense\n",
        "inv_sellingprice = df[df['sellingprice']<100]\n",
        "drop_val(inv_sellingprice)"
      ],
      "metadata": {
        "id": "nFjPjkh5F5c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixing mmr column\n",
        "\n",
        "# Delete null values or mmr values that have values below 100\n",
        "inv_mmr = df[(df['mmr'].isna()) | (df['mmr']<100)]\n",
        "drop_val(inv_mmr)\n",
        "\n",
        "# I dropped it because mmr value have the exact number at some website for that year, \n",
        "# so if its null, it can't be filled by any information in this dataset\n",
        "# mmr under 100 dropped because it just doesn't make sense for used cars have mmr price under 100"
      ],
      "metadata": {
        "id": "zL5sVmjfF-uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixing odometer column\n",
        "\n",
        "# Delete odometer that have value below 10.0 or above 9000000\n",
        "odometer_inv = df[(df['odometer']<10.0) | (df['odometer']>900000.0)]\n",
        "drop_val(odometer_inv)\n",
        "\n",
        "# Dropped because it is sure that almost every car doesn't have that value in its odometer"
      ],
      "metadata": {
        "id": "d49tmLFGGAbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Show Correlation Between Columns to Get More Insight**"
      ],
      "metadata": {
        "id": "-XPTFhkbGCCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.heatmap(df.corr(),linewidth=0.5,annot=True)\n",
        "plt.title('Correlation Between Numerical Columns',fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FCLC0g29GCy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the heatmap, we can conclude that:\n",
        "\n",
        "* year and odometer have high negative correlation, it means higher the year so lower the odometer\n",
        "* mmr and sellingprice have high positive correlation, it means higher the mmr so sellingprice is high too\n",
        "* other columns have a little correlation with each other since its value is only between 0.4 to 0.6"
      ],
      "metadata": {
        "id": "xMkSy0IBGGGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check again numerical columns after fixing some columns\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "ilFAGAl5GLzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping condition is null because there are no good ways to fill it\n",
        "condition_null = df[(df['condition'].isna())]\n",
        "drop_val(condition_null)"
      ],
      "metadata": {
        "id": "uHoT4wtSGNsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill Odometer \n",
        "# Its filled value taken from median odometer per year\n",
        "medianOdoByYear= df.groupby('year').median()['odometer']\n",
        "def fillOdo(x):\n",
        "    forfill = []\n",
        "    for i in df['year']:\n",
        "        if x['odometer'] > 0:\n",
        "            return x['odometer']\n",
        "        else:\n",
        "            if x['year'] > 0:\n",
        "                return medianOdoByYear.loc[x['year']]\n",
        "            else:\n",
        "                return np.nan\n",
        "df['odometer'] = df.apply(fillOdo,axis=1)"
      ],
      "metadata": {
        "id": "CC2xSUquGPk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fill 'model' Column**"
      ],
      "metadata": {
        "id": "qt4gdfk6GRQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take null value from model column\n",
        "modelNull = df[df['model'].isna()]\n",
        "\n",
        "# Check the similiarity from make and trim columns in rows that have null value of models\n",
        "model_trim = []\n",
        "temptrim = []\n",
        "for i in modelNull['make'].unique():\n",
        "    for j in modelNull['trim'].unique():\n",
        "        model_trim.append(i)\n",
        "        try:\n",
        "            cek = df[(df['make']==str(i)) & (df['trim']==str(j)) & (df['body']=='sedan')]['model'].value_counts().index[0]\n",
        "            temptrim.append(cek)\n",
        "        except:\n",
        "            temptrim.append(np.nan)\n",
        "            \n",
        "print(temptrim)\n",
        "print(model_trim)"
      ],
      "metadata": {
        "id": "tjEbI1WNGTcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_del = []\n",
        "idx_to_change = []\n",
        "ls_7 = []\n",
        "for idx,val in list(enumerate(df['model'])):\n",
        "    if str(val) == 'nan':\n",
        "        idx_to_change.append(idx)\n",
        "        \n",
        "        for item in df[df['make'] == 'audi'].index:\n",
        "            idx_del.append(item)            \n",
        "\n",
        "# Make temporary dataframe for rows to filled         \n",
        "tempdf = df.iloc[idx_to_change]\n",
        "\n",
        "# Find cars that have '7' in their trim\n",
        "for item in modelNull['trim'].unique():\n",
        "    if re.search('7.+',item):\n",
        "        ls_7.append(item)\n",
        "\n",
        "# Filled model that have '7' in their trim to '7 Series'\n",
        "for i in ls_7:\n",
        "    df.loc[tempdf[tempdf['trim']==str(i)].index,'model'] = '7 series'            \n",
        "\n",
        "# Filled model that have '650i xdrive' in their trim to '6 series gran coupe'\n",
        "df.loc[tempdf[tempdf['trim']=='650i xdrive'].index,'model'] = '6 series gran coupe'   \n",
        "\n",
        "# Dropped because there are no value trim when make is 'audi' \n",
        "df.drop(idx_del,inplace=True)\n",
        "\n",
        "# Dropped if there are still null values\n",
        "model_null_idx = df[df['model'].isna()]\n",
        "drop_val(model_null_idx)"
      ],
      "metadata": {
        "id": "YV504k1vGWGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fill 'trim' Column**"
      ],
      "metadata": {
        "id": "jiGBrTiRGYVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trimNotNull = df.loc[df['trim'].notnull()][['make', 'model', 'trim']]\n",
        "trimNotNull['combined'] = trimNotNull['make'].str.cat(trimNotNull['model'].astype(str), sep=\"_\")\n",
        "trimNotNull.drop(['make', 'model'],1,inplace=True)"
      ],
      "metadata": {
        "id": "5ALpPGQFGX-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['combined'] = df['make'].str.cat(df['model'].astype(str), sep=\"_\")\n",
        "trimGroupby = trimNotNull.groupby('combined').first()['trim']\n",
        "\n",
        "def fillTrim(x):\n",
        "    for i in df['combined']:\n",
        "        if str(x['trim']) != 'nan':\n",
        "            return x['trim']\n",
        "        else:\n",
        "            try:\n",
        "                return trimGroupby.loc[x['combined']]\n",
        "            except:\n",
        "                return np.nan\n",
        "            \n",
        "df['trim'] = df.apply(fillTrim,axis=1)\n",
        "df.drop(['combined'],1,inplace=True)\n",
        "\n",
        "trim_null_idx = df[df['trim'].isna()]\n",
        "drop_val(trim_null_idx)"
      ],
      "metadata": {
        "id": "LBBmmUtNGbdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fill 'body' Column**"
      ],
      "metadata": {
        "id": "m3eweYrQGlau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bodyNotNull = df.loc[df['body'].notnull()][['make', 'model', 'trim', 'body']]\n",
        "bodyNotNull[\"combined\"] = bodyNotNull['make'].str.cat(bodyNotNull[['model','trim']].astype(str), sep=\"_\")\n",
        "bodyNotNull.drop(['make', 'model' , 'trim'],1,inplace=True)"
      ],
      "metadata": {
        "id": "i-R89GBZGmQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['combined'] = df['make'].str.cat(df[['model', 'trim']].astype(str), sep=\"_\")\n",
        "bodyGroupby = bodyNotNull.groupby('combined').agg(pd.Series.mode)['body']\n",
        "\n",
        "def fillBody(x):\n",
        "    for i in df['combined']:\n",
        "        if str(x['body']) != 'nan':\n",
        "            return x['body']\n",
        "        else:\n",
        "            try:\n",
        "                return bodyGroupby.loc[x['combined']]\n",
        "            except:\n",
        "                return np.nan\n",
        "            \n",
        "df['body'] = df.apply(fillBody,axis=1)\n",
        "df.drop(['combined'],1,inplace=True)\n",
        "\n",
        "body_null_idx = df[df['body'].isna()]\n",
        "drop_val(body_null_idx)"
      ],
      "metadata": {
        "id": "QBS6D3JhGn_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fill 'transmission' Column**"
      ],
      "metadata": {
        "id": "zbKnsF9VGq7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transNotNull = df.loc[df['transmission'].notnull()][['make', 'model', 'trim', 'body', 'transmission']]\n",
        "transNotNull[\"combined\"] = transNotNull['make'].str.cat(transNotNull[['model', 'trim', 'body']].astype(str), sep=\"_\")\n",
        "transNotNull.drop(['make', 'model', 'trim', 'body'],1,inplace=True)"
      ],
      "metadata": {
        "id": "trrwaV8WGpdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['combined'] = df['make'].str.cat(df[['model', 'trim', 'body']].astype(str), sep=\"_\")\n",
        "transGroupby = transNotNull.groupby('combined').first()['transmission']\n",
        "\n",
        "def fillTransmission(x):\n",
        "    for i in df['combined']:\n",
        "        if str(x['transmission']) != 'nan':\n",
        "            return x['transmission']\n",
        "        else:\n",
        "            try:\n",
        "                return transGroupby.loc[x['combined']]\n",
        "            except:\n",
        "                return np.nan\n",
        "            \n",
        "df['transmission'] = df.apply(fillTransmission,axis=1)\n",
        "df.drop(['combined'],1,inplace=True)\n",
        "\n",
        "trans_null_idx = df[df['transmission'].isna()]\n",
        "drop_val(trans_null_idx)"
      ],
      "metadata": {
        "id": "x3m8DVXHGvTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For three columns above (trim, body, transmission) have similiar way to filled at its null values. There are three steps that needed to complete filled null values:\n",
        "\n",
        "* Get rows that have no null values from the columns and make new dataframe contain information of the car that already concatenated.\n",
        "* Null value at the columns filled by looking at first value where data from 'combined' column in new dataframe is equal from data from df. This way is almost similiar with VLOOKUP in Microsoft Excel.\n",
        "* Drop the rest of the rows that still have null value in its columns."
      ],
      "metadata": {
        "id": "RnbShVu0GxbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix 'body' column values to make it more spesific\n",
        "for i in df['body'].unique():\n",
        "    if 'van' in i:\n",
        "        df.loc[df[df['body']==i].index,'body'] = 'van'\n",
        "    elif 'cab' in i:\n",
        "        df.loc[df[df['body']==i].index,'body'] = 'cab'\n",
        "    elif 'suv' in i:\n",
        "        df.loc[df[df['body']==i].index,'body'] = 'suv'\n",
        "    elif 'sedan' in i:\n",
        "        df.loc[df[df['body']==i].index,'body'] = 'sedan'\n",
        "    elif 'convertible' in i:\n",
        "        df.loc[df[df['body']==i].index,'body'] = 'convertible'\n",
        "    elif 'wagon' in i:\n",
        "        df.loc[df[df['body']==i].index,'body'] = 'wagon'\n",
        "    elif 'coupe' in i or 'koup' in i:\n",
        "        df.loc[df[df['body']==i].index,'body'] = 'coupe'"
      ],
      "metadata": {
        "id": "JQcoJLfZG13Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop all duplicates data if any\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "zRXct6_oG3ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recap Dataframe After Data Cleaning Process**"
      ],
      "metadata": {
        "id": "qPRe4m4sG3uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "svY7U4WzG5sZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "qNULG7r3G8Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "fn5QG2WwG9pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include='object')"
      ],
      "metadata": {
        "id": "PvAB_PGCG_hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save to CSV Files**"
      ],
      "metadata": {
        "id": "tTEK5p5sHBJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('Clean_CarAuctionPrices_Dataset.csv',index=False)"
      ],
      "metadata": {
        "id": "yaEwGAbkHCKG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}