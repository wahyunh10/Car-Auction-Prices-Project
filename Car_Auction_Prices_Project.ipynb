{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Car Auction Prices Project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNEZjuY3G8qQiFLBgNGMcbF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wahyunh10/Car-Auction-Prices-Project/blob/main/Car_Auction_Prices_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Car Auction Prices Project**"
      ],
      "metadata": {
        "id": "yKhrbC_qm4J9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this project, there are 4 steps that I do:**\n",
        "\n",
        "1. Data Preparation (Data Cleaning)\n",
        "  * Extract Raw Data\n",
        "  * Fill and Drop Null Values\n",
        "  * Standardization Values\n",
        "  * Load Clean Data to CSV and Local MySQL Database\n",
        "2. Exploration Data Analysis\n",
        "  * Find Insight using Matplotlib and Seaborn\n",
        "  * Outlier Analysis\n",
        "  * Find Best and Worst Seller using Quantile Analysis\n",
        "3. Machine Learning Modelling\n",
        "  * Prediction Prices Cars using Regression\n",
        "  * Clustering Quality of Cars using KMeans Clustering\n",
        "4. Hypothesis Testing using MannWhitneyU"
      ],
      "metadata": {
        "id": "bMe6_PsoocaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains historical car auction sales prices, scraped from the outside internet sources collected in 2015. This dataset taken from kaggle (https://www.kaggle.com/tunguz/used-car-auction-prices)."
      ],
      "metadata": {
        "id": "qMuGyksyo34q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset contains 491641 rows and 15 columns:\n",
        "\n",
        "* year : information of year production of the car\n",
        "* make : brand of the car\n",
        "* model : model of the brand car\n",
        "* trim : spesific model of the car\n",
        "* body : body type of the car\n",
        "* transmission : transmission type of the car\n",
        "* vin : unique id of the car\n",
        "* state : code state where the transaction happened\n",
        "* condition : rating condition of the car\n",
        "* odometer : total distance of the car\n",
        "* color : body color of the car\n",
        "* interior : interior color of the car\n",
        "* seller : place that sold the car\n",
        "* mmr : market price of the car\n",
        "* sellingprice : price of the car\n",
        "* saledate : date when the car sold"
      ],
      "metadata": {
        "id": "whXzS5CAo6yS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preparation**"
      ],
      "metadata": {
        "id": "E4u2NqEet2rJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3ca7QtQHm1KU"
      },
      "outputs": [],
      "source": [
        "# Import needed libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import raw data from csv**"
      ],
      "metadata": {
        "id": "u-jeL3XKt9tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_source = pd.read_csv(\".csv\",sep='\\t')\n",
        "df_source.head()"
      ],
      "metadata": {
        "id": "Wh-FJGdjuBVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check length of every row in dataset\n",
        "idx = []\n",
        "for i in range (df_source.shape[0]):\n",
        "    l = len(df_source.iloc[i][0].split(','))\n",
        "    idx.append(l)\n",
        "    \n",
        "# Give temporary name columns \n",
        "tempcol = []\n",
        "for i in range((max(idx))):\n",
        "    tempcol.append(i)\n",
        "\n",
        "df_csv = pd.read_csv(\"car_prices.csv\",names=tempcol) \n",
        "\n",
        "# Extract first row value to make it into columns name\n",
        "col = []\n",
        "tempcol = ['temp1','temp2']\n",
        "for i in df_csv.iloc[0].values:\n",
        "    if str(i) != 'nan':\n",
        "        col.append(i)\n",
        "col.extend(tempcol) \n",
        "\n",
        "df = df_csv.drop(0,axis=0)\n",
        "df.columns=col\n",
        "df.reset_index(drop=True,inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "X2C1jrTTEU7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check data after columns problem solved**"
      ],
      "metadata": {
        "id": "en09n5OkEXnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_info():\n",
        "    listkolom=[]\n",
        "    for i in (df.columns):\n",
        "        listkolom.append(i)\n",
        "\n",
        "    listtipe=[]\n",
        "    for i in (df.columns):\n",
        "        listtipe.append(df[i].dtypes)\n",
        "\n",
        "    nullmany = df.isnull().sum().values\n",
        "\n",
        "    nullpctx = []\n",
        "    for i in nullmany:\n",
        "        nullpctx.append(round(i/len(df),4)*100)\n",
        "\n",
        "    unik = df.nunique().values\n",
        "\n",
        "    samp = []\n",
        "    for i in df.columns:\n",
        "        samp.append(df[i].sample().values)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'dataFeatures' : listkolom,\n",
        "        'dataType' : listtipe,\n",
        "        'null' : nullmany,\n",
        "        'nullpct' : nullpctx,\n",
        "        'unique' : unik,\n",
        "        'SampleValue' : samp\n",
        "    })\n",
        "\n",
        "data_info()"
      ],
      "metadata": {
        "id": "i1KiEZc8EYY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> It looks that data successfully stored into dataframe, and only have 21 anomaly rows that stored in temp1 column. Column temp2 is empty and will be deleted later.\n",
        "\n"
      ],
      "metadata": {
        "id": "jf8Dc-wIEdRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Process to tackle columns overlapping problem**"
      ],
      "metadata": {
        "id": "bTTQMYcCE2GE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to make all value has lowercase word\n",
        "def LowerVal(col):\n",
        "    newval = []\n",
        "    for i in df[col].values:\n",
        "        if str(i)=='nan':\n",
        "            newval.append(np.nan)\n",
        "        else:\n",
        "            cap = str(i).lower()\n",
        "            newval.append(cap)\n",
        "    df[col]=newval"
      ],
      "metadata": {
        "id": "elZPnyPGEaOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to all objects columns\n",
        "col_to_clean = df.select_dtypes(include='object').columns\n",
        "for i in col_to_clean:\n",
        "    LowerVal(i)"
      ],
      "metadata": {
        "id": "IVQXC2Z0E5sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix some value in 'make' columns\n",
        "makeFix = []\n",
        "for i in range(df.shape[0]):\n",
        "    if str(df['make'][i]) == 'nan':\n",
        "        makeFix.append(np.nan)\n",
        "    else:\n",
        "        newMake = df['make'][i].split()[0]\n",
        "        makeFix.append(newMake)\n",
        "\n",
        "df['make'] = makeFix\n",
        "\n",
        "df.loc[df[df['make']=='Mercedes-b'].index,'make'] = 'Mercedes-benz'\n",
        "df.loc[df[df['make']=='Mercedes'].index,'make'] = 'Mercedes-benz'\n",
        "df.loc[df[df['make']=='Land'].index,'make'] = 'Landrover'\n",
        "df.loc[df[df['make']=='Chev'].index,'make'] = 'Chevrolet'"
      ],
      "metadata": {
        "id": "ZTG9E-nuE7ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['transmission'].value_counts()"
      ],
      "metadata": {
        "id": "6gEkoqVtE9Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> From transmission column value, we can take conclusion rows that have 'sedan' as it value is the anomaly rows."
      ],
      "metadata": {
        "id": "pyG_kta0FB5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take rows that have 'sedan' as it value\n",
        "enum=list(enumerate(df['transmission']=='sedan'))\n",
        "idx_inv = []\n",
        "for idx,val in enum:\n",
        "    if val == True:\n",
        "        idx_inv.append(idx)\n",
        "        \n",
        "inv_data = df.iloc[idx_inv]\n",
        "\n",
        "# drop body column in invalid dataframe\n",
        "inv_data.drop(['body'],1,inplace=True)\n",
        "inv_data.head()"
      ],
      "metadata": {
        "id": "j5IoTRdJFE0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> body column in invalid dataframe dropped because it contain wrong information"
      ],
      "metadata": {
        "id": "ZHI-Ebu9FGrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['temp2'],1,inplace=True)\n",
        "inv_data.columns=df.columns\n",
        "\n",
        "# Re-fill value for invalid rows\n",
        "newval = []\n",
        "for i in range (inv_data.shape[0]):\n",
        "    listedval = list(inv_data.iloc[i].values)\n",
        "    newval.append(listedval)\n",
        "    \n",
        "df.iloc[idx_inv] = newval\n",
        "df.drop(['temp1'],1,inplace=True)\n",
        "\n",
        "# Check dataframe after problem invalid value rows solved \n",
        "df.info()"
      ],
      "metadata": {
        "id": "1niPSepVFHnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Cleaning Process**"
      ],
      "metadata": {
        "id": "znOM-mqkFVKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check total null values in every column\n",
        "pd.isna(df).sum()"
      ],
      "metadata": {
        "id": "eHKgektOFiOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check and replace if there are '-' value in dataset.\n",
        "def StripVal(col):\n",
        "    newval = []\n",
        "    for i in df[col].values:\n",
        "        if str(i)=='—':\n",
        "            newval.append(np.nan)\n",
        "        else:\n",
        "            newval.append(i)\n",
        "    df[col]=newval"
      ],
      "metadata": {
        "id": "IPh9EXlOFkRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply StripVal function to every columns object\n",
        "col_obj = df.select_dtypes('object').columns\n",
        "for i in col_obj:\n",
        "    StripVal(i)"
      ],
      "metadata": {
        "id": "19RZgEL2Fki5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to drop selected rows\n",
        "def drop_val(col):\n",
        "    idx_to_drop = []\n",
        "    for i in col.index:\n",
        "        idx_to_drop.append(i)\n",
        "\n",
        "    df.drop(idx_to_drop,inplace=True)\n",
        "    df.reset_index(drop=True,inplace=True)"
      ],
      "metadata": {
        "id": "KDxhO-ZzFl7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If the car have no information about all of make, model, body, and trim columns so we cannot describe what car is it.\n",
        "\n",
        "dataNull = df[(df['make'].isna()) & (df['model'].isna()) & (df['body'].isna()) & (df['trim'].isna())]\n",
        "\n",
        "drop_val(dataNull)"
      ],
      "metadata": {
        "id": "EvKClqxbFodP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If the car does not have color or interior information, dropped because it haven't got enough information.\n",
        "\n",
        "data_no_color = df[(df['color'].isna()) | (df['interior'].isna())]\n",
        "\n",
        "drop_val(data_no_color)"
      ],
      "metadata": {
        "id": "rhkIjZLlFo-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change data type to number\n",
        "\n",
        "df['year'] = df['year'].astype('int')\n",
        "df['mmr'] = df['mmr'].astype('int')\n",
        "df['sellingprice'] = df['sellingprice'].astype('int')\n",
        "df['condition'] = df['condition'].astype('float')\n",
        "df['odometer'] = df['odometer'].astype('float')"
      ],
      "metadata": {
        "id": "FrVL2MB1Fqws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fixing date columns\n",
        "\n",
        "fixed_date = []\n",
        "for i in range(len(df['saledate'])):\n",
        "    date = df.saledate[i][:15]\n",
        "    fixed_date.append(date)\n",
        "    \n",
        "df['saledate'] = fixed_date\n",
        "df['saledate'] = pd.to_datetime(df['saledate'])\n",
        "\n",
        "date_not_use = df[(df['saledate'] < '2014-12-01')]  # Deleting this data because there aren't enough data for that range of date \n",
        "drop_val(date_not_use)                              # It can cause trouble to EDA and Machine Learning modelling"
      ],
      "metadata": {
        "id": "xcaAdSXJFss1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "wJA56rTKFwM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This table above show us statistical descriptive of the data, it give insight that some columns have unusual and potentially wrong data. For example:\n",
        "\n",
        "* odometer have min and max value too far from the quartile, make the spread of data become ugly and have too large outlier\n",
        "* mmr have minimal value so little that have to check again\n",
        "* sellingprice have min and max value too far from the quartile like odometer column."
      ],
      "metadata": {
        "id": "2Mlt8KaOFzZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixing Sellingprice column\n",
        "\n",
        "# Change column that have maximum sellingprice because its value is too big\n",
        "# After some check, there is only one column that has maximum sellingprice value, that column have 22800 mmr\n",
        "wr_val_sellingprice = df[df['sellingprice']==df['sellingprice'].max()].index\n",
        "\n",
        "# Because the value of mmr and sellingprice is usually not too far, so I remove one '0' at this cell of sellingprice column\n",
        "df.loc[wr_val_sellingprice,['sellingprice']] = 23000  \n",
        "\n",
        "# Delete data that have sellingprice below 100, because it doesn't make sense\n",
        "inv_sellingprice = df[df['sellingprice']<100]\n",
        "drop_val(inv_sellingprice)"
      ],
      "metadata": {
        "id": "nFjPjkh5F5c8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}